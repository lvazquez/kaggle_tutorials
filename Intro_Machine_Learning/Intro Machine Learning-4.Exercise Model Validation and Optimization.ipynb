{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Model Validation\n",
    "\n",
    "## Recap\n",
    "\n",
    "You've built a model. In this exercise you will test how good your model is.\n",
    "\n",
    "Run the cell below to set up your coding environment where the previous exercise left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First in-sample predictions: [208500. 181500. 223500. 140000. 250000.]\n",
      "Actual target values for those homes: [208500, 181500, 223500, 140000, 250000]\n"
     ]
    }
   ],
   "source": [
    "# Code you have previously used to load data\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Path of the file to read\n",
    "iowa_file_path = '../input/home-data-for-ml-course/iowa_train.csv'\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "\n",
    "y = home_data.SalePrice\n",
    "feature_columns = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', \n",
    "                   'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[feature_columns]\n",
    "\n",
    "# Specify Model\n",
    "iowa_model = DecisionTreeRegressor()\n",
    "# Fit Model\n",
    "iowa_model.fit(X, y)\n",
    "\n",
    "print(\"First in-sample predictions:\", iowa_model.predict(X.head()))\n",
    "print(\"Actual target values for those homes:\", y.head().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Split Your Data\n",
    "\n",
    "Use the `train_test_split` function to split up your data.\n",
    "\n",
    "Give it the argument `random_state=1` so you know what to expect when verifying your code.\n",
    "\n",
    "Recall, your features are loaded in the DataFrame **X** and your target is loaded in **y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_test_split function and uncomment\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# fill in and uncomment\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Specify and Fit the Model\n",
    "\n",
    "Create a **DecisionTreeRegressor** model and fit it to the relevant data. Set `random_state` to 1 again when creating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First in-sample predictions: [307000. 223500. 145000. 155000. 140000.]\n",
      "Actual target values for those homes: [307000, 223500, 145000, 155000, 140000]\n"
     ]
    }
   ],
   "source": [
    "# Specify the model\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# Fit model\n",
    "iowa_model.fit(train_X, train_y)\n",
    "print(\"First in-sample predictions:\", iowa_model.predict(train_X.head()))\n",
    "print(\"Actual target values for those homes:\", train_y.head().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make Predictions with Validation data\n",
    "\n",
    "Predict with validation data and inspect your predictions and actual values from validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First validation predictions: [186500. 184000. 130000.  92000. 164500.]\n",
      "Actual validation values: [231500, 179500, 122000, 84500, 142000]\n"
     ]
    }
   ],
   "source": [
    "# Predict with all validation observations\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "\n",
    "# print the top few validation predictions\n",
    "print(\"First validation predictions:\", val_predictions[:5])\n",
    "# print the top few actual prices from validation data\n",
    "print(\"Actual validation values:\", val_y.head().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice that is different from what you saw with in-sample predictions (which are printed after the top code cell in this page).\n",
    "\n",
    "Do you remember why validation predictions differ from in-sample (or training) predictions? This is an important idea from the last lesson.\n",
    "\n",
    "## Step 4: Calculate the Mean Absolute Error in Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 29652.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "val_mae = mean_absolute_error(val_y, val_predictions)\n",
    "\n",
    "# uncomment following line to see the validation_mae\n",
    "print(\"MAE: {:.2f}\".format(val_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is that MAE good? There isn't a general rule for what values are good that applies across applications. But you'll see how to use (and improve) this number in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Compare Different Tree Sizes\n",
    "\n",
    "We have seen the `max_leaf_nodes` argument provides a very sensible way to control overfitting vs underfitting in the Decision Tree algorithm. \n",
    "\n",
    "In this exercise we will use the following a utility function to help compare MAE scores from different values for `max_leaf_nodes`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    mae = mean_absolute_error(val_y, model.predict(val_X))\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a loop that tries the values for max_leaf_nodes from a list of possible values in `candidate_max_leaf_nodes`. Call the `get_mae` function on each value and store the output in some way that allows you to select the value of `max_leaf_nodes` that gives the most accurate model on your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5\t\t Mean Absolute Error: 35044.51\n",
      "Max leaf nodes: 25\t\t Mean Absolute Error: 29016.41\n",
      "Max leaf nodes: 50\t\t Mean Absolute Error: 27405.93\n",
      "Max leaf nodes: 100\t\t Mean Absolute Error: 27282.51\n",
      "Max leaf nodes: 250\t\t Mean Absolute Error: 27893.82\n",
      "Max leaf nodes: 500\t\t Mean Absolute Error: 29454.19\n",
      "Best max_leaf_nodes: 100\n"
     ]
    }
   ],
   "source": [
    "candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n",
    "# Write loop to find the ideal tree size from candidate_max_leaf_nodes\n",
    "min_mae = 1.0e10\n",
    "# Store the best value of max_leaf_nodes (it will be either 5, 25, 50, 100, 250 or 500)\n",
    "best_tree_size = 5\n",
    "for mln in candidate_max_leaf_nodes:\n",
    "    mae = get_mae(mln, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: {:d}\\t\\t Mean Absolute Error: {:0.2f}\".format(mln, mae))\n",
    "    if mae < min_mae:\n",
    "        min_mae = mae\n",
    "        best_tree_size = mln\n",
    "print(\"Best max_leaf_nodes: {:d}\".format(best_tree_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Fit Model Using All Data\n",
    "\n",
    "Now you know the best tree size. If you were going to deploy this model in practice, you would make it even more accurate by using all of the data and keeping that tree size.  That is, you don't need to hold out the validation data now that you've made all your modeling decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_leaf_nodes=100, random_state=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in argument to make optimal size and uncomment\n",
    "final_model = DecisionTreeRegressor(max_leaf_nodes=best_tree_size, random_state=0)\n",
    "\n",
    "# fit the final model and uncomment the next two lines\n",
    "final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've tuned this model and improved your results. But we are still using Decision Tree models, which are not very sophisticated by modern machine learning standards. \n",
    "\n",
    "In the next step you will learn to use Random Forests to improve your models even more.\n",
    "\n",
    "## Step 7: Use a Random Forest\n",
    "\n",
    "Data science isn't always this easy. But replacing the decision tree with a Random Forest is going to be an easy win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE for Random Forest Model: 21857.16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the model. Set random_state to 1\n",
    "rf_model = RandomForestRegressor(random_state=1)\n",
    "# fit your model\n",
    "rf_model.fit(train_X, train_y)\n",
    "val_predictions = rf_model.predict(val_X)\n",
    "\n",
    "# Calculate the mean absolute error of your Random Forest model on the validation data\n",
    "rf_val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "\n",
    "print(\"Validation MAE for Random Forest Model: {:.2f}\".format(rf_val_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
